{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WmKLiSXebsfM",
        "vNZUFFGt0EV2",
        "UMhmlOj9pAAj",
        "80sNCWRLCYOx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guillermo-rv/ML/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMwqBzaSO-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 4"
      ],
      "metadata": {
        "id": "WmKLiSXebsfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "y2SotRX_Z3ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Reading the data\n",
        "df_liga = pd.read_csv(\"laliga_player_stats.csv\")\n",
        "\n",
        "# Step 2: Removing the columns with the word \"Goals\" or \"Penalties\"\n",
        "# Step 2.1.: Finding the columns\n",
        "lst_cols_remove = df_liga.columns[df_liga.columns.str.contains(\"Goals\", case=True)] # List with cols \"goals\"\n",
        "lst_cols_remove_penalties = df_liga.columns[df_liga.columns.str.contains(\"Penalties\", case=True)] # List with cols \"penalties\"\n",
        "lst_cols_remove = lst_cols_remove.append(lst_cols_remove_penalties) # Append \"penalties\" to \"goals\"\n",
        "# Step 2.2: Removing them from the dataset\n",
        "X = df_liga.drop(columns=lst_cols_remove) # 49 columns\n",
        "\n",
        "# Step 3: Creating X and y\n",
        "X = X.replace(\"%\", \"\", regex=True) # We remove the % to\n",
        "X = X[X.columns[4:]] # Removing the first 4 columns\n",
        "X = X.apply(pd.to_numeric) # Transforming to numeric all the columns!\n",
        "y = df_liga['Goals scored'] # Our variable to predict\n",
        "\n",
        "# Step 4: Splitting training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
        "\n",
        "# Step 5: Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "KRoUymnEbr_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "def adjusted_r2_score(y_true, y_pred, n_features): # n_features needs to be the number of columns of X (X_train or X_test)\n",
        "                                                   # X_train.shape[1] // X_test.shape[1]\n",
        "  r2 = r2_score(y_true, y_pred)\n",
        "  N = y_true.shape[0] # len(y_true)\n",
        "  p = n_features\n",
        "  return 1 - (((1-r2)*(N-1)) / (N-p-1))\n",
        "\n",
        "def print_errors (y_true, y_pred, n_features): # n_features is the number of columns of X (X_train.shape[1])\n",
        "  print(\"R2: \" + str(r2_score(y_true, y_pred)))  # The best result is 1.0\n",
        "  print(\"Adjusted R2: \" + str(adjusted_r2_score(y_true, y_pred, n_features))) # The best result is 1.0\n",
        "  print(\"MSE: \" + str(mean_squared_error(y_true, y_pred))) # The best value is 0.0\n",
        "  print(\"MAE: \" + str(mean_absolute_error(y_true, y_pred))) # The best value is 0.0"
      ],
      "metadata": {
        "id": "aVfm6m2QZ5VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ],
      "metadata": {
        "id": "numYRQbCceRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(0.1) # feature selectors (selecting some variables/features/columns from the X)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "# METRICS!! BEST PARAMETERS\n",
        "# Training\n",
        "y_train_pred = lasso.predict(X_train_scaled)\n",
        "print(\"Training metrics\")\n",
        "print_errors(y_train, y_train_pred, X_train_scaled.shape[1])\n",
        "# Test\n",
        "y_test_pred = lasso.predict(X_test_scaled)\n",
        "print(\"\\nTest metrics\")\n",
        "print_errors(y_test, y_test_pred, X_test_scaled.shape[1]) # X_train_scaled.shape[1] also works"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe6ZPM_LeLiZ",
        "outputId": "7b8e30a8-ea35-4653-b834-8b5821fdd8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics\n",
            "R2: 0.8954385736399293\n",
            "Adjusted R2: 0.882439044957326\n",
            "MSE: 1.270757252850962\n",
            "MAE: 0.6481259414131052\n",
            "\n",
            "Test metrics\n",
            "R2: 0.8767823948678781\n",
            "Adjusted R2: 0.8151735923018172\n",
            "MSE: 1.5397449483923829\n",
            "MAE: 0.7587273966613549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(lasso.coef_) # info: importance of the columns & columns to remove (redundant)\n",
        "X_cols = pd.DataFrame(X.columns) # Creating a new dataframe with the name of the columns in the rows\n",
        "X_cols['coefs'] = pd.DataFrame(lasso.coef_) # Adding one column to the dataframe with the coefficients from Lasso\n",
        "X_cols[X_cols['coefs']!=0.0] # Filtering by coefs not 0.0"
      ],
      "metadata": {
        "id": "I8Ann_sreMt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of selecting the columns using Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "selectModel = SelectFromModel(lasso, prefit=True) # We use prefit=True because lasso was already fitted.\n",
        "                                                    # If not, set prefit to False and fit the selectModel object with X_train_scaled, y_train\n",
        "X_train_scaled_lasso = selectModel.transform(X_train_scaled)\n",
        "X_test_scaled_lasso = selectModel.transform(X_test_scaled)\n",
        "\n",
        "print(selectModel.get_feature_names_out(X.columns))"
      ],
      "metadata": {
        "id": "z6qJ8oyClL2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee5ffd9-0b3b-4204-956d-eaf8fcbfd436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Games where substituted' 'Unsuccessful aerial challenges' 'Offsides'\n",
            " 'Shots on target' 'From inside the area' 'From outside the area'\n",
            " 'Crosses']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3"
      ],
      "metadata": {
        "id": "iVt5en6BkEeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# WITH ALL COLUMNS\n",
        "print(\"WITH ALL COLUMNS\")\n",
        "knn_v1 = KNeighborsRegressor() # Default parameters\n",
        "knn_v1.fit(X_train_scaled, y_train)\n",
        "print(\"\\nTraining metrics\")\n",
        "y_train_pred_knn = knn_v1.predict(X_train_scaled)\n",
        "print_errors(y_train, y_train_pred_knn, X_train_scaled.shape[1])\n",
        "print(\"\\nTest metrics\")\n",
        "y_test_pred_knn = knn_v1.predict(X_test_scaled)\n",
        "print_errors(y_test, y_test_pred_knn, X_train_scaled.shape[1])\n",
        "\n",
        "# LASSO COLUMNS\n",
        "print(\"\\n\\nLASSO COLUMNS\")\n",
        "knn_v2 = KNeighborsRegressor() # Default parameters\n",
        "knn_v2.fit(X_train_scaled_lasso, y_train)\n",
        "print(\"\\nTraining metrics\")\n",
        "y_train_pred_knn2 = knn_v2.predict(X_train_scaled_lasso)\n",
        "print_errors(y_train, y_train_pred_knn2, X_train_scaled_lasso.shape[1]) # now we have 7 columns\n",
        "print(\"\\nTest metrics\")\n",
        "y_test_pred_knn2 = knn_v2.predict(X_test_scaled_lasso)\n",
        "print_errors(y_test, y_test_pred_knn2, X_train_scaled_lasso.shape[1]) # now we have 7 columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmbLlS3Ki4aD",
        "outputId": "1b5ae327-b091-4f5f-b357-5d06aa7e7b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH ALL COLUMNS\n",
            "\n",
            "Training metrics\n",
            "R2: 0.8164679862395957\n",
            "Adjusted R2: 0.7936504926369509\n",
            "MSE: 2.230503597122302\n",
            "MAE: 0.6796163069544364\n",
            "\n",
            "Test metrics\n",
            "R2: 0.7968869854786736\n",
            "Adjusted R2: 0.6953304782180105\n",
            "MSE: 2.5381294964028775\n",
            "MAE: 0.9151079136690649\n",
            "\n",
            "\n",
            "LASSO COLUMNS\n",
            "\n",
            "Training metrics\n",
            "R2: 0.8190962991704955\n",
            "Adjusted R2: 0.8160001478115554\n",
            "MSE: 2.198561151079137\n",
            "MAE: 0.6148681055155875\n",
            "\n",
            "Test metrics\n",
            "R2: 0.7924194203066626\n",
            "Adjusted R2: 0.7813273282619804\n",
            "MSE: 2.5939568345323747\n",
            "MAE: 0.8201438848920864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVkioN3ElIgP",
        "outputId": "50c8540e-3f3a-415a-802f-35f3f6b5aa18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    556.000000\n",
              "mean       1.696043\n",
              "std        3.503828\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        2.000000\n",
              "max       36.000000\n",
              "Name: Goals scored, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 5"
      ],
      "metadata": {
        "id": "vNZUFFGt0EV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "OqG85dX50GqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "my_params = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C': [0.001, 0.01, 0.1, 1],\n",
        "    'gamma': [0.01, 0.1, 1],\n",
        "    'epsilon': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "svr = SVR()\n",
        "\n",
        "clf = GridSearchCV(svr, my_params) # r2 // accuracy\n",
        "clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "cXszfkUNmD88",
        "outputId": "296f9dde-e379-495b-994d-bf55ac91b46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVR(),\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 1], 'epsilon': [0.01, 0.1, 1],\n",
              "                         'gamma': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf']})"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVR(),\n",
              "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1], &#x27;epsilon&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;gamma&#x27;: [0.01, 0.1, 1], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVR(),\n",
              "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1], &#x27;epsilon&#x27;: [0.01, 0.1, 1],\n",
              "                         &#x27;gamma&#x27;: [0.01, 0.1, 1], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best params: \" + str(clf.best_params_))\n",
        "print(\"TRAINING METRICS\")\n",
        "y_train_pred = clf.predict(X_train_scaled)\n",
        "print_errors(y_train, y_train_pred, X_train_scaled.shape[1])\n",
        "print(\"TEST METRICS\")\n",
        "y_test_pred = clf.predict(X_test_scaled)\n",
        "print_errors(y_test, y_test_pred, X_train_scaled.shape[1])\n",
        "\n",
        "# Benchmark algorithms!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgqxVode0zi8",
        "outputId": "370d7fe7-387b-4d64-d946-d1f6566f5cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 0.1, 'epsilon': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
            "TRAINING METRICS\n",
            "R2: 0.891015792163769\n",
            "Adjusted R2: 0.8774664041625079\n",
            "MSE: 1.3245082567752142\n",
            "MAE: 0.6310345410157989\n",
            "TEST METRICS\n",
            "R2: 0.8529989213134939\n",
            "Adjusted R2: 0.7794983819702408\n",
            "MSE: 1.836946660934354\n",
            "MAE: 0.7859985737269664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ],
      "metadata": {
        "id": "XPJMDTYy5aij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "PzXkA7DY6emb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_grid_mlp = {\n",
        "    'hidden_layer_sizes' : [[50, 25], # We have 50 neurons in the first hidden layer and 25 neurons in the second (last) hidden layer\n",
        "                           [25, 10],\n",
        "                           [50] # We only have 1 hidden layer that has 50 neurons\n",
        "                           ]\n",
        "}\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "mlp = MLPRegressor(max_iter=500, learning_rate=\"adaptive\", early_stopping=True,\n",
        "                   tol=0.00001, alpha=0.001, random_state=42)\n",
        "\n",
        "clf_mlp = GridSearchCV(mlp, my_grid_mlp)\n",
        "clf_mlp.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "L1u3kR8Y2Xzl",
        "outputId": "e28c8109-56bd-488f-92e9-719808dc1bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=MLPRegressor(alpha=0.001, early_stopping=True,\n",
              "                                    learning_rate='adaptive', max_iter=500,\n",
              "                                    random_state=2, tol=1e-05),\n",
              "             param_grid={'hidden_layer_sizes': [[50, 25], [25, 10], [50]]})"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MLPRegressor(alpha=0.001, early_stopping=True,\n",
              "                                    learning_rate=&#x27;adaptive&#x27;, max_iter=500,\n",
              "                                    random_state=2, tol=1e-05),\n",
              "             param_grid={&#x27;hidden_layer_sizes&#x27;: [[50, 25], [25, 10], [50]]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MLPRegressor(alpha=0.001, early_stopping=True,\n",
              "                                    learning_rate=&#x27;adaptive&#x27;, max_iter=500,\n",
              "                                    random_state=2, tol=1e-05),\n",
              "             param_grid={&#x27;hidden_layer_sizes&#x27;: [[50, 25], [25, 10], [50]]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0.001, early_stopping=True, learning_rate=&#x27;adaptive&#x27;,\n",
              "             max_iter=500, random_state=2, tol=1e-05)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0.001, early_stopping=True, learning_rate=&#x27;adaptive&#x27;,\n",
              "             max_iter=500, random_state=2, tol=1e-05)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best params: \" + str(clf_mlp.best_params_))\n",
        "print(\"TRAINING METRICS\")\n",
        "y_train_pred = clf_mlp.predict(X_train_scaled)\n",
        "print_errors(y_train, y_train_pred, X_train_scaled.shape[1])\n",
        "print(\"TEST METRICS\")\n",
        "y_test_pred = clf_mlp.predict(X_test_scaled)\n",
        "print_errors(y_test, y_test_pred, X_train_scaled.shape[1])"
      ],
      "metadata": {
        "id": "9pwf2hzM6vUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try different parameters -> set a random_state\n",
        "# MLP: use more specific neural networks libraries (pytorch, tensorflow,...)"
      ],
      "metadata": {
        "id": "KSXQ8RiEjEQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVING A MODEL\n",
        "import joblib"
      ],
      "metadata": {
        "id": "RuYYB4ySjqb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(clf_mlp, \"my_mlp_model.pkl\") # Save the model as .pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlqB2yLIg4sS",
        "outputId": "4e11ccd4-4bc2-4ca3-844d-55df3e0c5857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_mlp_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_saved_model = joblib.load(\"my_mlp_model.pkl\") # Load the model"
      ],
      "metadata": {
        "id": "R6OVyqT6kLnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TEST METRICS\")\n",
        "y_test_pred = my_saved_model.predict(X_test_scaled)\n",
        "print_errors(y_test, y_test_pred, X_train_scaled.shape[1])"
      ],
      "metadata": {
        "id": "QZiuZz_aka1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 6"
      ],
      "metadata": {
        "id": "UMhmlOj9pAAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_insurance = pd.read_csv(\"insurance.csv\")"
      ],
      "metadata": {
        "id": "Vci8vtOWoD0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In sklearn, models based on trees don't work (for the moment) with categorical columns.\n",
        "# Theoretically, models based on trees handle perfectly these types of columns.\n",
        "# In H2O library (python) you can use categorical columns in models based on trees. [Consider it if you have lot of categories]"
      ],
      "metadata": {
        "id": "2xQgbD_wq5gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In sklearn you can convert categories to 0 or 1 using pd.dummies (pandas) or OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "pqMFYeHtuyMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_insurance.drop(columns=\"charges\")\n",
        "y = df_insurance['charges']"
      ],
      "metadata": {
        "id": "GGnY0VUVx4Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_toEncoder = ['sex', 'smoker', 'region']\n",
        "cols_toScale = ['age']\n",
        "cols_transformer = ColumnTransformer(transformers=[('my_onehotenc', OneHotEncoder(), cols_toEncoder) # Apply OneHotEncoder only to cols_toEncode\n",
        "                               # , ('my_scaler', StandardScaler(), cols_toScale) # Be careful! fit with train and transform with train and test\n",
        "                                ],\n",
        "                  remainder=\"passthrough\") # The columns that are not in the transformers will go as they are\n",
        "X_transformed = cols_transformer.fit_transform(X)\n",
        "#X_transformed.shape # 3 for regions, 1 new for sex, 1 new for smoker"
      ],
      "metadata": {
        "id": "Z0SGqY2Lvu4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the columns names\n",
        "cols_withTransformer = cols_transformer.transformers_[0][1].get_feature_names_out(cols_toEncoder) # Columns after the OneHotEncoder\n",
        "                                                # ([0] because it's the first transformer and [1] because it's the object OneHotEncoder itself)\n",
        "cols_withTransformer = list(cols_withTransformer)\n",
        "cols_withoutTransformer = ['age','bmi','children'] # Columns that are in the remainder of the ColumnTransformer\n",
        "cols_newDataFrame = cols_withTransformer + cols_withoutTransformer # Adding one list to the other\n",
        "X_transformed_df = pd.DataFrame(X_transformed, columns=cols_newDataFrame) # Creating the dataframe with the columns names"
      ],
      "metadata": {
        "id": "BJ8M8WEt8e_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y)\n",
        "# Split X and y\n",
        "# Split training and test: X_train, X_test, y_train, y_test\n",
        "# Preprocessing (Scaler!!!!, OneHotEncoder - depends)"
      ],
      "metadata": {
        "id": "Vdk5a2pbqNsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor(max_leaf_nodes=5)\n",
        "dt.fit(X_train, y_train)\n",
        "print(\"Metrics TRAINING\")\n",
        "y_train_pred = dt.predict(X_train)\n",
        "print_errors(y_train, y_train_pred, X_train.shape[1])\n",
        "print(\"\\nMetrics TEST\")\n",
        "y_test_pred = dt.predict(X_test)\n",
        "print_errors(y_test, y_test_pred, X_train.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gku1QqwvqOxU",
        "outputId": "b4a3cf7c-f15b-4664-eadf-05f6cb24124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics TRAINING\n",
            "R2: 0.8350750496869388\n",
            "Adjusted R2: 0.8332443993807394\n",
            "MSE: 24046403.585564\n",
            "MAE: 3208.576531636226\n",
            "\n",
            "Metrics TEST\n",
            "R2: 0.8358829489424062\n",
            "Adjusted R2: 0.8302938233645935\n",
            "MSE: 24413669.209773634\n",
            "MAE: 3189.9851251496157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_test_pred).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcOHCUUfyKg4",
        "outputId": "1a60ab7f-4175-4b90-ec20-959cc97024a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5345.116045     158\n",
              "12359.521230    107\n",
              "21412.018360     31\n",
              "44384.138093     27\n",
              "36068.060530     12\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(y_test, y_test_pred)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7-V5jOG7MX6",
        "outputId": "57f27115-0e9a-4790-a600-c0d981f49407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.24718827697121"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ID7zGRkh5GgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from drive.MyDrive.Colab_Notebooks.IntakeFebruary2024_ML_exercises.s00_useful_functions_supervised import *"
      ],
      "metadata": {
        "id": "lblCb6Zg6aw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_feature_importances_tree(dt, X_transformed_df)"
      ],
      "metadata": {
        "id": "ciGcsb2i_uuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_tree_regression(dt, X_transformed_df.columns) # Getting the plot of the tree"
      ],
      "metadata": {
        "id": "i-JhcnhE6qW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 7: Ensembles"
      ],
      "metadata": {
        "id": "80sNCWRLCYOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALING\n",
        "X_train_df = pd.DataFrame(X_train, columns=cols_newDataFrame)\n",
        "X_test_df = pd.DataFrame(X_test, columns=cols_newDataFrame)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_df[['age', 'bmi', 'children']])"
      ],
      "metadata": {
        "id": "VPBO7IKt_kdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming with the scaling\n",
        "X_train_scaled_nums = scaler.transform(X_train_df[['age','bmi','children']])\n",
        "X_test_scaled_nums = scaler.transform(X_test_df[['age','bmi','children']])\n",
        "\n",
        "# Dropping the columns that we scaled\n",
        "X_train_df = X_train_df.drop(columns=['age','bmi','children'])\n",
        "X_test_df = X_test_df.drop(columns=['age','bmi','children'])\n",
        "\n",
        "# Creating a new DataFrame with the columns that we scaled\n",
        "X_train_scaled_nums = pd.DataFrame(X_train_scaled_nums, columns=['age','bmi','children'])\n",
        "X_test_scaled_nums = pd.DataFrame(X_test_scaled_nums, columns=['age','bmi','children'])\n",
        "\n",
        "# Adding the columns that we scaled to the DataFrame\n",
        "X_train_df[['age', 'bmi', 'children']] = X_train_scaled_nums\n",
        "X_test_df[['age', 'bmi', 'children']] = X_test_scaled_nums"
      ],
      "metadata": {
        "id": "gw82jxJaCoFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classes (LR, SVM, KNN)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Define the models --> The optimal way of doing it is: finding the best parameters for each estimator individually (GridSearchCV)\n",
        "    # Using those parameters to define the estimators of the VotingRegressor\n",
        "reg1 = LinearRegression()\n",
        "reg2 = SVR() # SVR(kernel=\"linear\")... # you can change the parameters if you want\n",
        "reg3 = KNeighborsRegressor()\n",
        "\n",
        "# Import the models with the parameters in the VotingRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "voting = VotingRegressor(estimators=[('my_linearregressor', reg1),\n",
        "                            ('my_svr', reg2),\n",
        "                            ('my_knn', reg3)],\n",
        "                         weights=[0.70, 0.10, 0.20]  # The LR will have more impact of the predictions of the VotingRegressor\n",
        "                )\n",
        "voting.fit(X_train_df, y_train) # We fit only the VotingRegressor (not the individual estimators)\n",
        "y_train_voting = voting.predict(X_train_df) # Prediction of the training\n",
        "print(\"Errors TRAINING\")\n",
        "print_errors(y_train, y_train_voting, X_train_df.shape[1])\n",
        "print(\"Errors TEST\")\n",
        "y_test_voting = voting.predict(X_test_df)\n",
        "print_errors(y_test, y_test_voting, X_train_df.shape[1]) # last parameter is the # of columns of our X (we need them for adjusted R2)"
      ],
      "metadata": {
        "id": "v56WZc5BEV9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ee423d-4881-437a-d0ca-fb9ed6f84394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors TRAINING\n",
            "R2: 0.7724978854186896\n",
            "Adjusted R2: 0.7699726349036599\n",
            "MSE: 33170285.35347191\n",
            "MAE: 3863.0254185885206\n",
            "Errors TEST\n",
            "R2: 0.7627796698955704\n",
            "Adjusted R2: 0.7547009589632214\n",
            "MSE: 35288342.26353762\n",
            "MAE: 4035.0686721912184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Regressor --> you need a final estimator (model)\n",
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
        "# SAME AS WITH VOTINGREGRESSOR: Obtain the best parameters for the individual model with GridSearchCV before\n",
        "# creating the stacking regressor\n",
        "\n",
        "stacking = StackingRegressor(estimators = [('lr', reg1), ('svm', reg2), ('knn', reg3)],\n",
        "                  final_estimator = RandomForestRegressor())\n",
        "\n",
        "stacking.fit(X_train_df, y_train) # We fit only the StackingRegressor (not the individual estimators)\n",
        "y_train_stacking = stacking.predict(X_train_df) # Prediction of the training\n",
        "print(\"Errors TRAINING\")\n",
        "print_errors(y_train, y_train_stacking, X_train_df.shape[1])\n",
        "print(\"Errors TEST\")\n",
        "y_test_stacking = stacking.predict(X_test_df)\n",
        "print_errors(y_test, y_test_stacking, X_train_df.shape[1]) # last parameter is the # of columns of our X (we need them for adjusted R2)"
      ],
      "metadata": {
        "id": "P00zXqfmEvSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0b8fc5-a57b-45cd-f5a6-02cba47f1831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors TRAINING\n",
            "R2: 0.794486083546255\n",
            "Adjusted R2: 0.7922048998116524\n",
            "MSE: 29964359.959581345\n",
            "MAE: 3462.657253785224\n",
            "Errors TEST\n",
            "R2: 0.7815582086697382\n",
            "Adjusted R2: 0.7741190145377479\n",
            "MSE: 32494890.693934686\n",
            "MAE: 3791.9240784011936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_reg1 = 10\n",
        "y_pred_reg2 = 13\n",
        "y_pred_reg3 = 14\n",
        "\n"
      ],
      "metadata": {
        "id": "hPqnLkjJlomP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 8"
      ],
      "metadata": {
        "id": "vnfqxMeejLn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yQ_PVITgjNIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Read data\n",
        "df_liga = pd.read_csv(\"laliga_player_stats.csv\")\n",
        "\n",
        "# Step 2: Create the label (value to predict/classify)\n",
        "df_liga['categories_goals'] = np.where(df_liga['Goals scored']>=10, 'cat1', 'cat0')\n",
        "#print(\"Unbalance in the target:\" + str(df_liga['categories_goals'].value_counts()))\n",
        "print(\"\\nPercentage of cat1 in the dataset: \" + str((df_liga['categories_goals'].value_counts()['cat1']*100)/len(df_liga)))\n",
        "\n",
        "# Step 3: Divide X and y\n",
        "X = df_liga.drop(columns=['categories_goals'])\n",
        "X = X[['Minutes played', 'Percentage of games played', 'Percentage of games where substituted', 'Passes', 'Assists', 'Shots', 'Crosses']].replace(\"%\", \"\", regex=True)\n",
        "X[['Percentage of games played', 'Percentage of games where substituted']] = X[['Percentage of games played', 'Percentage of games where substituted']].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "y = df_liga[['categories_goals']]\n",
        "\n",
        "#  Step 4: Split in training/test considering the categories (stratifying)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25, stratify=y)\n",
        "print(\"\\nPercentage of cat1 in training set: \" + str((y_train.value_counts()['cat1']*100)/len(y_train)))\n",
        "print(\"\\nPercentage cat1 in test set: \" + str((y_test.value_counts()['cat1']*100)/len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzJPxnIBjOy9",
        "outputId": "66a7c0fe-69eb-447a-8176-53e254320824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Percentage of cat1 in the dataset: 3.776978417266187\n",
            "\n",
            "Percentage of cat1 in training set: 3.8560411311053984\n",
            "\n",
            "Percentage cat1 in test set: 3.592814371257485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def print_resultados(y_actual, y_pred):\n",
        "  print(\"\\tAccuracy score: \" + str(accuracy_score(y_actual, y_pred)))\n",
        "  print(\"\\tBalanced Accuracy score: \"+ str(balanced_accuracy_score(y_actual, y_pred)))"
      ],
      "metadata": {
        "id": "2XytOL2Dj2bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE with LogReg with default parameters\n",
        "print(\"**\\tLOGREG with DEFAULT parameters\\t**\")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipeline_logreg_base = Pipeline([#('scaler', StandardScaler()),  # 1º\n",
        "                                #(\"lg\", LogisticRegression(class_weight=\"balanced\"))]) # 2º\n",
        "                                # ('svc', SVC(class_weight=\"balanced\"))])\n",
        "                                ('my_rf', RandomForestClassifier(class_weight=\"balanced\"))])\n",
        "\n",
        "pipeline_logreg_base.fit(X_train, y_train['categories_goals'])\n",
        "\n",
        "print(\"\\nTraining results:\")\n",
        "print_resultados(y_train, pipeline_logreg_base.predict(X_train))\n",
        "\n",
        "print(\"\\nTest results:\")\n",
        "print_resultados(y_test, pipeline_logreg_base.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7-gYIWPkOTm",
        "outputId": "b18ddcb5-d11c-44ec-b642-559c607c8f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**\tLOGREG with DEFAULT parameters\t**\n",
            "\n",
            "Training results:\n",
            "\tAccuracy score: 1.0\n",
            "\tBalanced Accuracy score: 1.0\n",
            "\n",
            "Test results:\n",
            "\tAccuracy score: 0.9580838323353293\n",
            "\tBalanced Accuracy score: 0.5771221532091098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train, pipeline_logreg_base.predict(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRtmXCt2kVsN",
        "outputId": "cfd10c81-a8a7-4045-ae7c-bc079348b6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[358,  16],\n",
              "       [  0,  15]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, pipeline_logreg_base.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFyPGAiPmCKi",
        "outputId": "1ae5df61-b401-4883-d419-790bad067d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[156,   5],\n",
              "       [  0,   6]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRA"
      ],
      "metadata": {
        "id": "Zel2QpRQrQeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "ojj5oAZDmH10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_pipeline = make_pipeline(\n",
        "                RandomUnderSampler(),  # Under-sampler strategy (you can use also an over-sampler strategy)\n",
        "                RandomForestClassifier()\n",
        "            )"
      ],
      "metadata": {
        "id": "w6U3fwFDrToZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_pipeline.fit(X_train, y_train['categories_goals'])\n",
        "y_train_preds = my_pipeline.predict(X_train)\n",
        "y_test_preds = my_pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "zbYRndi3sElU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test['predictions'] =  y_test_preds"
      ],
      "metadata": {
        "id": "tIhIw0onvFD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test['real'] = y_test"
      ],
      "metadata": {
        "id": "MqPCrF2_vbGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTRAINING\")\n",
        "print_resultados(y_train, y_train_preds)\n",
        "print(\"\\nTEST\")\n",
        "print_resultados(y_test, y_test_preds)"
      ],
      "metadata": {
        "id": "J3rBcV1GsXsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "balanced_rf = BalancedRandomForestClassifier()\n",
        "balanced_rf.fit(X_train, y_train['categories_goals'])\n",
        "\n",
        "y_train_preds = balanced_rf.predict(X_train)\n",
        "y_test_preds = balanced_rf.predict(X_test)\n",
        "\n",
        "print(\"\\nTRAINING\")\n",
        "print_resultados(y_train, y_train_preds)\n",
        "print(\"\\nTEST\")\n",
        "print_resultados(y_test, y_test_preds)"
      ],
      "metadata": {
        "id": "nKclPSmMsnFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9loIY5xotmh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}